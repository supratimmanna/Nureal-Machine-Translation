{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural_machine_Translation_3.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNE5Hmg1hoV+mMrEqEre8PG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/supratimmanna/Nureal-Machine-Translation/blob/master/Neural_machine_Translation_seq2seq.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QIav0U-uGvO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import string\n",
        "from string import digits\n",
        "import re\n",
        "from sklearn.utils import shuffle\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import LSTM, Input, Dense,Embedding\n",
        "from keras.models import Model,load_model\n",
        "from keras.preprocessing.text import one_hot\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.models import model_from_json\n",
        "import pickle as pkl\n",
        "import numpy as np\n",
        "from keras.utils import to_categorical\n",
        "from numpy import array"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Gs5tyQKUbeq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('mar.txt','r', encoding=\"utf-8\") as f:\n",
        "  data = f.readlines()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RwaMwY5UcsO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "13d37558-7e63-4571-e609-127d09305d41"
      },
      "source": [
        "data[:3]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Go.\\tजा.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #3138228 (sabretou)\\n',\n",
              " 'Run!\\tपळ!\\tCC-BY 2.0 (France) Attribution: tatoeba.org #906328 (papabear) & #3138217 (sabretou)\\n',\n",
              " 'Run!\\tधाव!\\tCC-BY 2.0 (France) Attribution: tatoeba.org #906328 (papabear) & #3138218 (sabretou)\\n']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqT0Tcopxhek",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "1b9fed9e-5830-4aff-a4b3-e25ac1188a44"
      },
      "source": [
        "with open('mar.txt','r', encoding=\"utf-8\") as f:\n",
        "  data = f.readlines()\n",
        "#uncleaned_data_list = data.split('\\n')\n",
        "uncleaned_data_list = data[:38695]\n",
        "english_word = []\n",
        "marathi_word = []\n",
        "# cleaned_data_list = []\n",
        "for word in uncleaned_data_list:\n",
        "  english_word.append(word.split('\\t')[:-1][0])\n",
        "  marathi_word.append(word.split('\\t')[:-1][1])\n",
        "  \n",
        "print(marathi_word[:3])\n",
        "\n",
        "language_data = pd.DataFrame(columns=['English','Marathi'])\n",
        "language_data['English'] = english_word\n",
        "language_data['Marathi'] = marathi_word\n",
        "\n",
        "# saving to csv\n",
        "language_data.to_csv('language_data.csv', index=False)\n",
        "\n",
        "# loading data from csv\n",
        "language_data = pd.read_csv('language_data.csv')\n",
        "\n",
        "# remove puntuation\n",
        "def remove_punc(text_list):\n",
        "  table = str.maketrans('', '', string.punctuation)\n",
        "  removed_punc_text = []\n",
        "  for sent in text_list:\n",
        "    sentance = [w.translate(table) for w in sent.split(' ')]\n",
        "    removed_punc_text.append(' '.join(sentance))\n",
        "  return removed_punc_text\n",
        "\n",
        "english_text = language_data['English'].values\n",
        "marathi_text = language_data['Marathi'].values\n",
        "english_text_ = [x.lower() for x in english_text]\n",
        "marathi_text_ = [x.lower() for x in marathi_text]\n",
        "\n",
        "# Text preprocessing\n",
        "english_text_ = [re.sub(\"'\",'',x) for x in english_text_]\n",
        "marathi_text_ = [re.sub(\"'\",'',x) for x in marathi_text_]\n",
        "\n",
        "english_text_ = remove_punc(english_text_)\n",
        "marathi_text_ = remove_punc(marathi_text_)\n",
        "\n",
        "# removing the digits from english sentances\n",
        "remove_digits = str.maketrans('', '', digits)\n",
        "removed_digits_text = []\n",
        "for sent in english_text_:\n",
        "  sentance = [w.translate(remove_digits) for w in sent.split(' ')]\n",
        "  removed_digits_text.append(' '.join(sentance))\n",
        "english_text_ = removed_digits_text\n",
        "\n",
        "# removing the digits from the marathi sentances\n",
        "marathi_text_ = [re.sub(\"[२३०८१५७९४६]\",\"\",x) for x in marathi_text_]\n",
        "marathi_text_ = [re.sub(\"[\\u200d]\",\"\",x) for x in marathi_text_]\n",
        "\n",
        "# removing the stating and ending whitespaces\n",
        "english_text_ = [x.strip() for x in english_text_]\n",
        "marathi_text_ = [x.strip() for x in marathi_text_]\n",
        "\n",
        "# Putting the start and end words in the marathi sentances\n",
        "marathi_text_ = [\"start \" + x + \" end\" for x in marathi_text_]\n",
        "\n",
        "# function to build a tokenizer\n",
        "def tokenization(lines):\n",
        "      tokenizer = Tokenizer()\n",
        "      tokenizer.fit_on_texts(lines)\n",
        "      return tokenizer\n",
        "\n",
        "# encode and pad sequences\n",
        "def encode_sequences(tokenizer, length, lines):\n",
        "          # integer encode sequences\n",
        "          seq = tokenizer.texts_to_sequences(lines)\n",
        "          # pad sequences with 0 values\n",
        "          seq = pad_sequences(seq, maxlen=length, padding='post')\n",
        "          return seq\n",
        "\n",
        "# one hot encode target sequence\n",
        "def encode_output(sequences, vocab_size):\n",
        "  ylist = list()\n",
        "  for sequence in sequences:\n",
        "    encoded = to_categorical(sequence, num_classes=vocab_size)\n",
        "    ylist.append(encoded)\n",
        "  y = array(ylist)\n",
        "  y = y.reshape(sequences.shape[0], sequences.shape[1], vocab_size)\n",
        "  return y\n",
        "\n",
        "eng_tokenizer=tokenization(english_text_)\n",
        "mar_tokenizer=tokenization(marathi_text_)\n",
        "\n",
        "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
        "max_eng_length = max(len(line.split()) for line in english_text_)\n",
        "mar_vocab_size = len(mar_tokenizer.word_index) + 1\n",
        "max_mar_length = max(len(line.split()) for line in marathi_text_)\n",
        "max_mar_length,mar_vocab_size,max_eng_length,eng_vocab_size\n",
        "\n",
        "reverse_word_map_target = dict(map(reversed, mar_tokenizer.word_index.items()))\n",
        "\n",
        "X = english_text_\n",
        "Y = marathi_text_\n",
        "#Splitting the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size = 0.1)\n",
        "\n",
        "print(len(X_train))\n",
        "\n",
        "print(len(y_train))\n",
        "\n",
        "print(len(X_test))\n",
        "\n",
        "print(len(y_test))\n",
        "\n",
        "trainX = encode_sequences(eng_tokenizer, max_eng_length, X_train)\n",
        "trainY = encode_sequences(mar_tokenizer, max_mar_length,y_train)\n",
        "#target_output=encode_output(trainY,mar_vocab_size)\n",
        "\n",
        "testX = encode_sequences(eng_tokenizer, max_eng_length, X_test)\n",
        "testY = encode_sequences(eng_tokenizer, max_eng_length, y_test)\n",
        "#target_output=encode_output(testY,mar_vocab_size)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['जा.', 'पळ!', 'धाव!']\n",
            "34825\n",
            "34825\n",
            "3870\n",
            "3870\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36xudhZ1Vkh-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "864cc1b2-08c1-4343-b5d7-8ed4da1a7191"
      },
      "source": [
        "trainX.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(34825, 12)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxHGmCLdVBpO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generator_batch(X= X_train,Y=y_train, batch_size=128):\n",
        "  while True:\n",
        "    for j in range(0, len(X), batch_size):\n",
        "      encoder_data_input = np.zeros((batch_size,max_eng_length),dtype='float32') #metrix of batch_size*max_length_english\n",
        "      decoder_data_input = np.zeros((batch_size,max_mar_length),dtype='float32') #metrix of batch_size*max_length_marathi\n",
        "      decoder_target_input = np.zeros((batch_size,max_mar_length,mar_vocab_size),dtype='float32') # 3d array one hot encoder decoder target data\n",
        "      for i, (input_text,target_text) in enumerate(zip(X[j:j+batch_size],Y[j:j+batch_size])):\n",
        "        for t, word in enumerate(input_text.split()):\n",
        "          encoder_data_input[i,t] = eng_tokenizer.word_index[word] # Here we are storing the encoder \n",
        "                                                                      #seq in row here padding is done automaticaly as \n",
        "                                                                      #we have defined col as max_lenght\n",
        "        for t, word in enumerate(target_text.split()):\n",
        "          # if word == 'START_':\n",
        "          #   word = 'start'\n",
        "          # elif word == 'END_':\n",
        "          #   word = 'end'\n",
        "          decoder_data_input[i,t] = mar_tokenizer.word_index[word] # same for the decoder sequence\n",
        "          if t>0:\n",
        "            decoder_target_input[i,t-1,mar_tokenizer.word_index[word]] = 1 #target is one timestep ahead of decoder input because it does not have 'start tag'\n",
        "      # print(encoder_data_input.shape())\n",
        "      yield ([encoder_data_input,decoder_data_input],decoder_target_input)\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t89v3yKpVHT9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "latent_dim = 50\n",
        "# Define an input sequence and process it.\n",
        "encoder_inputs = Input(shape=(None,),name=\"encoder_inputs\")\n",
        "emb_layer_encoder = Embedding(eng_vocab_size,latent_dim, mask_zero=True)(encoder_inputs)\n",
        "encoder = LSTM(latent_dim, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder(emb_layer_encoder)\n",
        "# We discard `encoder_outputs` and only keep the states.\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = Input(shape=(None,),name=\"decoder_inputs\")\n",
        "# We set up our decoder to return full output sequences,\n",
        "# and to return internal states as well. We don't use the\n",
        "# return states in the training model, but we will use them in inference.\n",
        "emb_layer_decoder = Embedding(mar_vocab_size,latent_dim, mask_zero=True)(decoder_inputs)\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(emb_layer_decoder, initial_state=encoder_states)\n",
        "decoder_dense = Dense(mar_vocab_size, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Define the model that will turn\n",
        "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjoHzJlgVLOf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_samples = len(X_train)\n",
        "val_samples = len(X_test)\n",
        "batch_size = 128\n",
        "epochs = 10\n",
        "\n",
        "model.fit_generator(generator = generator_batch(X_train, y_train, batch_size = batch_size),\n",
        "                    steps_per_epoch = train_samples//batch_size,\n",
        "                    epochs=epochs)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}